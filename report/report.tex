\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb,amsfonts}
\usepackage{enumitem}
\usepackage[table]{xcolor}

\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2:}]}{\end{trivlist}}

\begin{document}

\title{\textbf{6.864 Final Project Report}}
%\author{\textbf{Tristan Thrush, Eric Wadkins}\\Massachusetts Institute of Technology\\\texttt{\{tristant, ewadkins\}@mit.edu}}
\author{Eric Wadkins, Tristan Thrush}
%\date{}
\maketitle

	%\emph{Note: All non-heuristic encoders are trained only on AskUbuntu training data.}
	\begin{center}
%		\begin{tabular}{|c||c|c|c|c||c|c|c|c|}
%			\hline
%			\cellcolor{gray!15}
%				& \multicolumn{4}{c||}{\cellcolor{gray!15}AskUbuntu Dev}
%				& \multicolumn{4}{c|}{\cellcolor{gray!15}AskUbuntu Test} \\ \hline
%			\cellcolor{gray!15}\textbf{Encoder} & \cellcolor{gray!15}\textbf{MAP} & \cellcolor{gray!15}\textbf{MRR}
%				& \cellcolor{gray!15}\textbf{P@1} & \cellcolor{gray!15}\textbf{P@5}
%				& \cellcolor{gray!15}\textbf{MAP} & \cellcolor{gray!15}\textbf{MRR}
%				& \cellcolor{gray!15}\textbf{P@1} & \cellcolor{gray!15}\textbf{P@5} \\ \hline\hline
%			\cellcolor{red!15}Bag-of-word-booleans* & 0.480 & 0.598 & 0.450 & 0.375 & 0.466 & 0.598 & 0.441 & 0.349 \\ \hline
%			\cellcolor{red!15}Bag-of-word-counts* & 0.459 & 0.561 & 0.386 & 0.363 & 0.468 & 0.612 & 0.468 & 0.357 \\ \hline
%			\cellcolor{red!15}Mean embeddings* & 0.457 & 0.554 & 0.397 & 0.360 & 0.450 & 0.583 & 0.425 & 0.349 \\ \hline\hline
%			\cellcolor{green!15}CNN & 0.532 & 0.631 & 0.481 & 0.408 & 0.555 & 0.692 & 0.548 & 0.430 \\ \hline
%			\cellcolor{green!15}LSTM & 0.526 & 0.681 & 0.561 & 0.413 & 0.508 & 0.609 & 0.452 & 0.394 \\ \hline
%		\end{tabular}
%		\begin{tabular}{|c||c|c|c|c||c|c|c|c|c|c|c|c|}
%			\hline
%			\cellcolor{gray!15}
%				& \multicolumn{6}{c||}{\cellcolor{gray!15}AskUbuntu Dev}
%				& \multicolumn{6}{c|}{\cellcolor{gray!15}AskUbuntu Test} \\ \hline
%			\cellcolor{gray!15}\textbf{Encoder} & \cellcolor{gray!15}\textbf{MAP} & \cellcolor{gray!15}\textbf{MRR}
%				& \cellcolor{gray!15}\textbf{P@1} & \cellcolor{gray!15}\textbf{P@5}
%				& \cellcolor{gray!15}\textbf{AUC} & \cellcolor{gray!15}\textbf{AUC(0.05)}
%				& \cellcolor{gray!15}\textbf{MAP} & \cellcolor{gray!15}\textbf{MRR}
%				& \cellcolor{gray!15}\textbf{P@1} & \cellcolor{gray!15}\textbf{P@5}
%				& \cellcolor{gray!15}\textbf{AUC} & \cellcolor{gray!15}\textbf{AUC(0.05)} \\ \hline\hline
%			\cellcolor{red!15}Bag-of-word-booleans* & 0.480 & 0.598 & 0.450 & 0.375 &  &  & 0.466 & 0.598 & 0.441 & 0.349 &  &  \\ \hline
%			\cellcolor{red!15}Bag-of-word-counts* & 0.459 & 0.561 & 0.386 & 0.363 &  &  & 0.468 & 0.612 & 0.468 & 0.357 &  &  \\ \hline
%			\cellcolor{red!15}Mean embeddings* & 0.457 & 0.554 & 0.397 & 0.360 &  &  & 0.450 & 0.583 & 0.425 & 0.349 &  &  \\ \hline\hline
%			\cellcolor{green!15}CNN & 0.532 & 0.631 & 0.481 & 0.408 &  &  & 0.555 & 0.692 & 0.548 & 0.430 &  &  \\ \hline
%			\cellcolor{green!15}LSTM & 0.526 & 0.681 & 0.561 & 0.413 &  &  & 0.508 & 0.609 & 0.452 & 0.394 &  &  \\ \hline
%		\end{tabular}
%		~\\~\\
%		\begin{tabular}{|c||c|c|c|c||c|c|c|c|}
%			\hline
%			\cellcolor{gray!15}
%				& \multicolumn{4}{c||}{\cellcolor{gray!15}Android Dev}
%				& \multicolumn{4}{c|}{\cellcolor{gray!15}Android Test} \\ \hline
%			\cellcolor{gray!15}\textbf{Encoder} & \cellcolor{gray!15}\textbf{MAP} & \cellcolor{gray!15}\textbf{MRR}
%				& \cellcolor{gray!15}\textbf{P@1} & \cellcolor{gray!15}\textbf{P@5}
%				& \cellcolor{gray!15}\textbf{MAP} & \cellcolor{gray!15}\textbf{MRR}
%				& \cellcolor{gray!15}\textbf{P@1} & \cellcolor{gray!15}\textbf{P@5} \\ \hline\hline
%			\cellcolor{red!15}Bag-of-word-booleans* & 0.332 & 0.337 & 0.227 & 0.090 & 0.351 & 0.355 & 0.238 & 0.095 \\ \hline
%			\cellcolor{red!15}Bag-of-word-counts* & 0.296 & 0.300 & 0.206 & 0.074 & 0.316 & 0.321 & 0.220 & 0.084 \\ \hline
%			\cellcolor{red!15}Mean embeddings* & 0.325 & 0.327 & 0.218 & 0.086 & 0.334 & 0.339 & 0.232 & 0.088 \\ \hline\hline
%			\cellcolor{green!15}CNN** & 0.386 & 0.388 & 0.270 & 0.101 & 0.394 & 0.397 & 0.281 & 0.103 \\ \hline
%			\cellcolor{green!15}LSTM** & 0.279 & 0.282 & 0.190 & 0.072 & 0.317 & 0.321 & 0.231 & 0.079 \\ \hline
%		\end{tabular}
%		~\\~\\
		\begin{tabular}{|c||c|c|c|c||c|c|}
			\hline
			\cellcolor{gray!15}
				& \multicolumn{6}{c|}{\cellcolor{gray!15}AskUbuntu Dev} \\ \hline
			\cellcolor{gray!15}\textbf{Encoder} & \cellcolor{gray!15}\textbf{MAP} & \cellcolor{gray!15}\textbf{MRR}
				& \cellcolor{gray!15}\textbf{P@1} & \cellcolor{gray!15}\textbf{P@5}
				& \cellcolor{gray!15}\textbf{AUC} & \cellcolor{gray!15}\textbf{AUC(0.05)} \\ \hline\hline
			\cellcolor{red!15}BOW-booleans* & 0.480 & 0.598 & 0.450 & 0.375 & 0.515 & 0.121 \\ \hline
			\cellcolor{red!15}BOW-counts* & 0.459 & 0.561 & 0.386 & 0.363 & 0.503 & 0.088 \\ \hline
			\cellcolor{red!15}Mean embeddings* & 0.457 & 0.554 & 0.397 & 0.360 & 0.518 & 0.040 \\ \hline
			\cellcolor{red!15}TF-IDF BOW* & 0.538 & 0.683 & 0.540 & 0.436 & 0.579 & 0.093 \\ \hline\hline
%			\cellcolor{green!15}CNN & 0.532 & 0.631 & 0.481 & 0.408 & 0.576 & 0.059 \\ \hline
%			\cellcolor{green!15}LSTM & 0.526 & 0.681 & 0.561 & 0.413 & 0.564 & 0.067 \\ \hline
			\cellcolor{green!15}CNN & 0.560 & 0.691 & 0.566 & 0.432 & 0.595 & 0.068 \\ \hline
			\cellcolor{green!15}LSTM & 0.526 & 0.681 & 0.561 & 0.413 & 0.564 & 0.067 \\ \hline
			\hline
			\cellcolor{gray!15}
				& \multicolumn{6}{c|}{\cellcolor{gray!15}AskUbuntu Test} \\ \hline
			\cellcolor{gray!15}\textbf{Encoder} & \cellcolor{gray!15}\textbf{MAP} & \cellcolor{gray!15}\textbf{MRR}
				& \cellcolor{gray!15}\textbf{P@1} & \cellcolor{gray!15}\textbf{P@5}
				& \cellcolor{gray!15}\textbf{AUC} & \cellcolor{gray!15}\textbf{AUC(0.05)} \\ \hline\hline
			\cellcolor{red!15}BOW-booleans* & 0.466 & 0.598 & 0.441 & 0.349 & 0.546 & 0.125 \\ \hline
			\cellcolor{red!15}BOW-counts* & 0.468 & 0.612 & 0.468 & 0.357 & 0.534 & 0.094 \\ \hline
			\cellcolor{red!15}Mean embeddings* & 0.450 & 0.583 & 0.425 & 0.349 & 0.522 & 0.051 \\ \hline
			\cellcolor{red!15}TF-IDF BOW* & 0.555 & 0.686 & 0.538 & 0.405 & 0.612 & 0.107 \\ \hline\hline
%			\cellcolor{green!15}CNN & 0.555 & 0.692 & 0.548 & 0.430 & 0.597 & 0.061 \\ \hline
%			\cellcolor{green!15}LSTM & 0.508 & 0.609 & 0.452 & 0.394 & 0.563 & 0.057 \\ \hline
			\cellcolor{green!15}CNN & 0.577 & 0.722 & 0.608 & 0.435 & 0.613 & 0.078 \\ \hline
			\cellcolor{green!15}LSTM & 0.508 & 0.609 & 0.452 & 0.394 & 0.563 & 0.057 \\ \hline
			\hline
			\cellcolor{gray!15}
				& \multicolumn{6}{c|}{\cellcolor{gray!15}Android Dev} \\ \hline
			\cellcolor{gray!15}\textbf{Encoder} & \cellcolor{gray!15}\textbf{MAP} & \cellcolor{gray!15}\textbf{MRR}
				& \cellcolor{gray!15}\textbf{P@1} & \cellcolor{gray!15}\textbf{P@5}
				& \cellcolor{gray!15}\textbf{AUC} & \cellcolor{gray!15}\textbf{AUC(0.05)} \\ \hline\hline
			\cellcolor{red!15}BOW-booleans* & 0.332 & 0.337 & 0.227 & 0.090 & 0.819 & 0.270 \\ \hline
			\cellcolor{red!15}BOW-counts* & 0.296 & 0.300 & 0.206 & 0.074 & 0.786 & 0.176 \\ \hline
			\cellcolor{red!15}Mean embeddings* & 0.325 & 0.327 & 0.218 & 0.086 & 0.797 & 0.172 \\ \hline
			\cellcolor{red!15}TF-IDF BOW* & 0.714 & 0.719 & 0.610 & 0.174 & 0.963 & 0.707 \\ \hline\hline
%			\cellcolor{green!15}CNN** & 0.386 & 0.388 & 0.270 & 0.101 & 0.869 & 0.231 \\ \hline
%			\cellcolor{green!15}LSTM** & 0.279 & 0.282 & 0.190 & 0.072 & 0.759 & 0.155 \\ \hline
			\cellcolor{green!15}CNN** & 0.450 & 0.454 & 0.347 & 0.114 & 0.892 & 0.278 \\ \hline
			\cellcolor{green!15}LSTM** & 0.279 & 0.282 & 0.190 & 0.072 & 0.759 & 0.155 \\ \hline
			\hline
			\cellcolor{gray!15}
				& \multicolumn{6}{c|}{\cellcolor{gray!15}Android Test} \\ \hline
			\cellcolor{gray!15}\textbf{Encoder} & \cellcolor{gray!15}\textbf{MAP} & \cellcolor{gray!15}\textbf{MRR}
				& \cellcolor{gray!15}\textbf{P@1} & \cellcolor{gray!15}\textbf{P@5}
				& \cellcolor{gray!15}\textbf{AUC} & \cellcolor{gray!15}\textbf{AUC(0.05)} \\ \hline\hline
			\cellcolor{red!15}BOW-booleans* & 0.351 & 0.355 & 0.238 & 0.095 & 0.841 & 0.290 \\ \hline
			\cellcolor{red!15}BOW-counts* & 0.316 & 0.321 & 0.220 & 0.084 & 0.794 & 0.172 \\ \hline
			\cellcolor{red!15}Mean embeddings* & 0.334 & 0.339 & 0.232 & 0.088 & 0.810 & 0.179 \\ \hline
			\cellcolor{red!15}TF-IDF BOW* & 0.744 & 0.750 & 0.647 & 0.178 & 0.965 & 0.739 \\ \hline\hline
%			\cellcolor{green!15}CNN** & 0.394 & 0.397 & 0.281 & 0.103 & 0.860 & 0.219 \\ \hline
%			\cellcolor{green!15}LSTM** & 0.317 & 0.321 & 0.231 & 0.079 & 0.775 & 0.187 \\ \hline
			\cellcolor{green!15}CNN** & 0.485 & 0.488 & 0.371 & 0.122 & 0.901 & 0.350 \\ \hline
			\cellcolor{green!15}LSTM** & 0.317 & 0.321 & 0.231 & 0.079 & 0.775 & 0.187 \\ \hline
		\end{tabular}
	\end{center}
	* Heuristic encoder (no learning involved, uses only evaluation data in evaluation) \\\\
	** Direct transfer -- No transfer learning is used. The models are trained only on the labeled AskUbuntu training data.

\section{Question Retrieval}
For the semi-supervised task of question retrieval, we've implemented two models to act as question encoders: a CNN and an LSTM.

\subsection{CNN Encoder}
The CNN consists of a single 1-dimensional convolutional layer, with an input of size 200 (the embedding length) and an output vector of size 667 (as used in \_\_\_), followed by a mean pooling layer. The convolutional layer outputs a state vector for each word of the input sequence. B the length of the input sequence is variable, we average the state vectors together using the aforementioned mean pooling layer, giving us a final vector representation of the entire sequence.

\subsection{LSTM Encoder}
The LSTM model we utilize is, more specifically, a single layer bidirectional LSTM. Similar to the CNN model described above, the LSTM layer outputs a variable number of state vectors. We average these together through the use of a mean pooling layer to arrive at the final encoding for the input sequence.

\subsection{Encoding Process}
We determined that the best method of encoding a question, which consists of a question title and a question body, is to encode the two sequences individually, and then average the two encodings. In the rare case that a question body is not provided for a given training sample, we use only the encoded title as the question encoding.\\

We found this method to be an improvement over other encoding methods, such as concatenating the title and body and encoding the combined sequence. In the case of this example, our chosen method was superior likely because of the variable length of the question title, which results in no fixed title-body boundary in a combined input sequence.\\

Also, as expected, using only one of the title or body as a representation of the question results in significantly decreased performance, as the model is limited to a single context, rather than the unique contexts presented in the titles and bodies of questions (titles tend to be a more concise description of the problem, but often miss many details; and bodies generally contain all relevant details, but also contain much extraneous information).

\subsection{Embeddings}
Talk about pruning of embeddings using CountVectorizer.

\subsection{Learning Procedure}
We train both models in the same manner. For each of the labeled AskUbuntu training sample questions, we select one similar question and 20 candidate questions, and encode all 22 questions using the encoding process described above. Next, we calculate the cosine similarity between the encodings of the sample question and the similar question, and the sample question and the 20 candidate questions. Finally, using PyTorch's MultiMarginLoss function, we calculate the loss and then update the model using the Adam optimizer. We also included the ability to train on batches (to reduce the volatility of the training process) -- updating the model on the combined loss of the entire batch, rather than after each individual sample.\\

Both models were trained with a learning rate of 0.1. We also chose to use a margin of 0.2 for the MultiMarginLoss. Without the use of a margin, we saw drastically reduced performance in both models, likely due to a lack of normalization.

\subsection{Results}
Put a table here...\\

Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.


\section{Transfer Learning}
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.

\subsection{Unsupervised Methods}
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

\subsection{Direct Transfer}
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

\subsection{Domain Adaptation}
\subsubsection{Gradient Reversal Layer}
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
\subsubsection{Other Methods}
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

\end{document}